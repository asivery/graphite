// This file was generated by lezer-generator. You probably shouldn't edit it.
import { LRParser } from "@lezer/lr";
export const parser = LRParser.deserialize({
  version: 14,
  states:
    "$UQVQPOOO[QPO'#C_OOQO'#C^'#C^QVQPOOOOQO'#Ck'#CkOaQQO,58yOOQO-E6i-E6iOoQQO'#CdOOQO'#Cc'#CcOtQPO'#CbOOQO1G.e1G.eO|QPO1G.eO!RQPO,59OO!ZQQO'#CmO!fQPO,58|OOQO7+$P7+$PO!nQQO'#ClO!sQPO1G.jOOQO1G.j1G.jOOQO,59X,59XOOQO-E6k-E6kOOQO,59W,59WOOQO-E6j-E6jOOQO7+$U7+$U",
  stateData:
    "!{~OdOS~OSPO~OTTO~OXVOYWO]WO^YO~OY[O~OZ]O^UX~O^_O~OZ`O[bO~OXVOYWO]WO~OZ]O^Ua~OYeO~OZ`O[gO~O",
  goto: "![bPPcgPPkntPPPPPPx!O!UTSORTQORRZTQXTRc]TWT]QRORURQa[RfaQ^XRd^",
  nodeNames:
    "⚠ Program ExprStmt Call Identifier ( Arguments Argument VertexCollection [ Vertex , ] Number )",
  maxTerm: 20,
  skippedNodes: [0],
  repeatNodeCount: 3,
  tokenData:
    "$O~RbX^!Zpq!Zxy#Oyz#T|}#Y!Q![#_!c!}#g!}#O#t#P#Q#y#T#o#g#y#z!Z$f$g!Z#BY#BZ!Z$IS$I_!Z$I|$JO!Z$JT$JU!Z$KV$KW!Z&FU&FV!Z~!`Yd~X^!Zpq!Z#y#z!Z$f$g!Z#BY#BZ!Z$IS$I_!Z$I|$JO!Z$JT$JU!Z$KV$KW!Z&FU&FV!Z~#TOT~~#YO^~~#_OZ~~#dP]~!Q![#_R#nQSPYQ!c!}#g#T#o#g~#yOX~~$OO[~",
  tokenizers: [0, 1],
  topRules: { Program: [0, 1] },
  tokenPrec: 0,
  termNames: {
    "0": "⚠",
    "1": "@top",
    "2": "ExprStmt",
    "3": "Call",
    "4": "Identifier",
    "5": '"("',
    "6": "Arguments",
    "7": "Argument",
    "8": "VertexCollection",
    "9": '"["',
    "10": "Vertex",
    "11": '","',
    "12": '"]"',
    "13": "Number",
    "14": '")"',
    "15": "statement+",
    "16": '("," Vertex)+',
    "17": '("," Argument)+',
    "18": "␄",
    "19": "%mainskip",
    "20": "space",
  },
});
