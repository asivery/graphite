// This file was generated by lezer-generator. You probably shouldn't edit it.
import { LRParser } from "@lezer/lr";
export const parser = LRParser.deserialize({
  version: 14,
  states:
    "$UQYQPOOO_QPO'#C`OOQO'#C_'#C_QYQPOOOOQO'#Cl'#ClOdQQO,58zOOQO-E6j-E6jOrQQO'#CeOOQO'#Cd'#CdOwQPO'#CcOOQO1G.f1G.fO!PQPO1G.fO!UQPO,59PO!^QQO'#CnO!iQPO,58}OOQO7+$Q7+$QO!qQQO'#CmO!vQPO1G.kOOQO1G.k1G.kOOQO,59Y,59YOOQO-E6l-E6lOOQO,59X,59XOOQO-E6k-E6kOOQO7+$V7+$V",
  stateData:
    "#O~OeOSPOS~OTPO~OUTO~OYVOZWO^WO_YO~OZ[O~O[]O_VX~O__O~O[`O]bO~OYVOZWO^WO~O[]O_Va~OZeO~O[`O]gO~O",
  goto: "!]cPPPdhPPlouPPPPPPy!P!VTSORTQORRZTQXTRc]TWT]QRORURQa[RfaQ^XRd^",
  nodeNames:
    "⚠ Comment Program ExprStmt Call Identifier ( Arguments Argument VertexCollection [ Vertex , ] Number )",
  maxTerm: 21,
  skippedNodes: [0, 1],
  repeatNodeCount: 3,
  tokenData:
    "$j~RcX^!^pq!^st#Rxy#jyz#o|}#t!Q![#y!c!}$R!}#O$`#P#Q$e#T#o$R#y#z!^$f$g!^#BY#BZ!^$IS$I_!^$I|$JO!^$JT$JU!^$KV$KW!^&FU&FV!^~!cYe~X^!^pq!^#y#z!^$f$g!^#BY#BZ!^$IS$I_!^$I|$JO!^$JT$JU!^$KV$KW!^&FU&FV!^~#WSP~OY#RZ;'S#R;'S;=`#d<%lO#R~#gP;=`<%l#R~#oOU~~#tO_~~#yO[~~$OP^~!Q![#yR$YQTPZQ!c!}$R#T#o$R~$eOY~~$jO]~",
  tokenizers: [0, 1],
  topRules: { Program: [0, 2] },
  tokenPrec: 0,
  termNames: {
    "0": "⚠",
    "1": "Comment",
    "2": "@top",
    "3": "ExprStmt",
    "4": "Call",
    "5": "Identifier",
    "6": '"("',
    "7": "Arguments",
    "8": "Argument",
    "9": "VertexCollection",
    "10": '"["',
    "11": "Vertex",
    "12": '","',
    "13": '"]"',
    "14": "Number",
    "15": '")"',
    "16": "statement+",
    "17": '("," Vertex)+',
    "18": '("," Argument)+',
    "19": "␄",
    "20": "%mainskip",
    "21": "space",
  },
});
